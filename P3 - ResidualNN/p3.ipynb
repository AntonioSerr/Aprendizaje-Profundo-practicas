{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <p style=\"font-size: 50px;\">Práctica 2: Residual Neural Networks</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "##### Definimos ResidualBlock especificada en la __figura 1__, que es una capa residual, posteriormente utilizada para crear la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"residualBlock.jpeg\" alt=\"Capa Residual\" width=\"600\">\n",
    "    <p>Figura 1: Capa residual </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:34:36.758499Z",
     "iopub.status.busy": "2024-11-29T21:34:36.758138Z",
     "iopub.status.idle": "2024-11-29T21:34:36.766744Z",
     "shell.execute_reply": "2024-11-29T21:34:36.765786Z",
     "shell.execute_reply.started": "2024-11-29T21:34:36.758468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, models\n",
    "\n",
    "class ResidualBlock(Model):\n",
    "    def __init__(self, input_channels, output_channels, strides=(1, 1)):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # Camino principal: BatchNorm → SiLU → Conv2D → BatchNorm → SiLU → Conv2D\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.activation1 = layers.Activation('swish')  # SiLU es 'swish' en Keras\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            output_channels, \n",
    "            kernel_size=3, \n",
    "            strides=strides, \n",
    "            padding=\"same\", \n",
    "            use_bias=False\n",
    "        )\n",
    "\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.activation2 = layers.Activation('swish')\n",
    "        self.conv2 = layers.Conv2D(\n",
    "            output_channels, \n",
    "            kernel_size=3, \n",
    "            strides=(1, 1), \n",
    "            padding=\"same\", \n",
    "            use_bias=False\n",
    "        )\n",
    "\n",
    "        # Conexión residual ajustada si los canales no coinciden\n",
    "        self.adjust_residual = None\n",
    "        if input_channels != output_channels:\n",
    "            self.adjust_residual = layers.Conv2D(\n",
    "                output_channels, \n",
    "                kernel_size=1, \n",
    "                strides=strides, \n",
    "                padding=\"same\", \n",
    "                use_bias=False\n",
    "            )\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        # Camino principal\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation1(x)\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Ajustar conexión residual si es necesario\n",
    "        if self.adjust_residual is not None:  # Caso 2: canales diferentes\n",
    "            residual = self.adjust_residual(residual)\n",
    "        \n",
    "        # Suma residual\n",
    "        return x + residual  # La suma funciona para ambos casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definimos la red ResidualNetwork especificada en la __figura 2__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"residualNetwork.jpeg\" alt=\"ResidualNetwork\" width=\"500\">\n",
    "    <p>Figura 2: ResidualNetwork </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:34:43.066940Z",
     "iopub.status.busy": "2024-11-29T21:34:43.066638Z",
     "iopub.status.idle": "2024-11-29T21:34:43.817850Z",
     "shell.execute_reply": "2024-11-29T21:34:43.817016Z",
     "shell.execute_reply.started": "2024-11-29T21:34:43.066915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,424</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">919,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m47,424\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m230,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m919,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m25,700\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,327,508</span> (16.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,327,508\u001b[0m (16.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,322,100</span> (16.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,322,100\u001b[0m (16.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,408</span> (21.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,408\u001b[0m (21.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "# Crear el modelo secuencial\n",
    "model = Sequential([\n",
    "    # Convolución inicial (sin BatchNorm ni activación en esta capa)\n",
    "    layers.Conv2D(16, kernel_size=3, strides=(1, 1), padding=\"same\", use_bias=False, input_shape=(32, 32, 3)),\n",
    "\n",
    "    # Grupo 1: 3 bloques residuales con canales 64\n",
    "    ResidualBlock(16, 64, strides=(1, 1)),\n",
    "    ResidualBlock(64, 64, strides=(1, 1)),\n",
    "    ResidualBlock(64, 64, strides=(1, 1)),\n",
    "\n",
    "    # Grupo 2: 3 bloques residuales con canales 128 (reducción de tamaño en el primer bloque)\n",
    "    ResidualBlock(64, 128, strides=(2, 2)),  # La reducción de tamaño aquí\n",
    "    ResidualBlock(128, 128, strides=(1, 1)),\n",
    "    ResidualBlock(128, 128, strides=(1, 1)),\n",
    "\n",
    "    # Grupo 3: 3 bloques residuales con canales 256 (reducción de tamaño en el primer bloque)\n",
    "    ResidualBlock(128, 256, strides=(2, 2)),  # La reducción de tamaño aquí\n",
    "    ResidualBlock(256, 256, strides=(1, 1)),\n",
    "    ResidualBlock(256, 256, strides=(1, 1)),\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('swish'),\n",
    "\n",
    "    # Promedio global y capa de salida\n",
    "    layers.GlobalAveragePooling2D(),  # Convierte (8, 8, 256) a un vector de tamaño 256\n",
    "    layers.Dense(100, activation=\"softmax\")  # CIFAR-100 tiene 100 clases\n",
    "])\n",
    "\n",
    "# Resumen del modelo para verificar las dimensiones\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "##### Para cargar los pesos de la red entrenada utilizaremos la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:34:46.263702Z",
     "iopub.status.busy": "2024-11-29T21:34:46.263295Z",
     "iopub.status.idle": "2024-11-29T21:34:46.271591Z",
     "shell.execute_reply": "2024-11-29T21:34:46.270655Z",
     "shell.execute_reply.started": "2024-11-29T21:34:46.263667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_weights(model, weight_file):\n",
    "    # Cargar los pesos desde el archivo utilizando pickle\n",
    "    with open(weight_file, 'rb') as f:\n",
    "        weights = pickle.load(f)\n",
    "\n",
    "    # Obtener todas las variables entrenables y no entrenables del modelo\n",
    "    all_vars = model.trainable_weights + model.non_trainable_weights\n",
    "\n",
    "    # Crear una lista de las variables y sus correspondientes pesos del archivo\n",
    "    weight_list = [(x, weights[x]) for x in sorted(weights.keys())]\n",
    "    weights = {}\n",
    "\n",
    "    # Iterar sobre todas las variables del modelo\n",
    "    for i, var in enumerate(all_vars):\n",
    "        # Obtener el nombre de la capa de la variable\n",
    "        aux = var.path.split('/')[-2:]\n",
    "        classname = '_'.join(aux[0].split('_')[:-1])\n",
    "        name = aux[1]\n",
    "\n",
    "        assigned = False\n",
    "        \n",
    "        # Buscar el peso que corresponde a la variable en la lista de pesos\n",
    "        for j, (key, value) in enumerate(weight_list):\n",
    "            if classname in key and name in key:\n",
    "                try:\n",
    "                    # Asignar el peso a la variable\n",
    "                    all_vars[i].assign(value)\n",
    "                    print(f'Asignando {key} a {var.name}')\n",
    "                except:\n",
    "                    continue\n",
    "                print('assinging', key, 'to', var.path)\n",
    "                del weight_list[j]\n",
    "                assigned = True\n",
    "                break\n",
    "\n",
    "        # Si no se pudo asignar el peso, lanzar una excepción\n",
    "        if not assigned:\n",
    "            raise Exception(var.path + ' cannot be loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Comprobamos que la precisión del modelo en CIFAR-100 es superior al 69 %. Para ello, preprocesamos el dataset y cargamos los pesos de ResidualNetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:34:48.405619Z",
     "iopub.status.busy": "2024-11-29T21:34:48.405012Z",
     "iopub.status.idle": "2024-11-29T21:34:54.121086Z",
     "shell.execute_reply": "2024-11-29T21:34:54.120203Z",
     "shell.execute_reply.started": "2024-11-29T21:34:48.405585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asignando conv2d_52/kernel a kernel\n",
      "assinging conv2d_52/kernel to sequential_3/conv2d_22/kernel\n",
      "Asignando batch_normalization_38/gamma a gamma\n",
      "assinging batch_normalization_38/gamma to sequential_3/residual_block_9/batch_normalization_19/gamma\n",
      "Asignando batch_normalization_38/beta a beta\n",
      "assinging batch_normalization_38/beta to sequential_3/residual_block_9/batch_normalization_19/beta\n",
      "Asignando conv2d_54/kernel a kernel\n",
      "assinging conv2d_54/kernel to sequential_3/residual_block_9/conv2d_23/kernel\n",
      "Asignando batch_normalization_39/gamma a gamma\n",
      "assinging batch_normalization_39/gamma to sequential_3/residual_block_9/batch_normalization_20/gamma\n",
      "Asignando batch_normalization_39/beta a beta\n",
      "assinging batch_normalization_39/beta to sequential_3/residual_block_9/batch_normalization_20/beta\n",
      "Asignando conv2d_55/kernel a kernel\n",
      "assinging conv2d_55/kernel to sequential_3/residual_block_9/conv2d_24/kernel\n",
      "Asignando conv2d_53/kernel a kernel\n",
      "assinging conv2d_53/kernel to sequential_3/residual_block_9/conv2d_25/kernel\n",
      "Asignando batch_normalization_40/gamma a gamma\n",
      "assinging batch_normalization_40/gamma to sequential_3/residual_block_10/batch_normalization_21/gamma\n",
      "Asignando batch_normalization_40/beta a beta\n",
      "assinging batch_normalization_40/beta to sequential_3/residual_block_10/batch_normalization_21/beta\n",
      "Asignando conv2d_56/kernel a kernel\n",
      "assinging conv2d_56/kernel to sequential_3/residual_block_10/conv2d_26/kernel\n",
      "Asignando batch_normalization_41/gamma a gamma\n",
      "assinging batch_normalization_41/gamma to sequential_3/residual_block_10/batch_normalization_22/gamma\n",
      "Asignando batch_normalization_41/beta a beta\n",
      "assinging batch_normalization_41/beta to sequential_3/residual_block_10/batch_normalization_22/beta\n",
      "Asignando conv2d_57/kernel a kernel\n",
      "assinging conv2d_57/kernel to sequential_3/residual_block_10/conv2d_27/kernel\n",
      "Asignando batch_normalization_42/gamma a gamma\n",
      "assinging batch_normalization_42/gamma to sequential_3/residual_block_11/batch_normalization_23/gamma\n",
      "Asignando batch_normalization_42/beta a beta\n",
      "assinging batch_normalization_42/beta to sequential_3/residual_block_11/batch_normalization_23/beta\n",
      "Asignando conv2d_58/kernel a kernel\n",
      "assinging conv2d_58/kernel to sequential_3/residual_block_11/conv2d_28/kernel\n",
      "Asignando batch_normalization_43/gamma a gamma\n",
      "assinging batch_normalization_43/gamma to sequential_3/residual_block_11/batch_normalization_24/gamma\n",
      "Asignando batch_normalization_43/beta a beta\n",
      "assinging batch_normalization_43/beta to sequential_3/residual_block_11/batch_normalization_24/beta\n",
      "Asignando conv2d_59/kernel a kernel\n",
      "assinging conv2d_59/kernel to sequential_3/residual_block_11/conv2d_29/kernel\n",
      "Asignando batch_normalization_44/gamma a gamma\n",
      "assinging batch_normalization_44/gamma to sequential_3/residual_block_12/batch_normalization_25/gamma\n",
      "Asignando batch_normalization_44/beta a beta\n",
      "assinging batch_normalization_44/beta to sequential_3/residual_block_12/batch_normalization_25/beta\n",
      "Asignando conv2d_61/kernel a kernel\n",
      "assinging conv2d_61/kernel to sequential_3/residual_block_12/conv2d_30/kernel\n",
      "Asignando batch_normalization_45/gamma a gamma\n",
      "assinging batch_normalization_45/gamma to sequential_3/residual_block_12/batch_normalization_26/gamma\n",
      "Asignando batch_normalization_45/beta a beta\n",
      "assinging batch_normalization_45/beta to sequential_3/residual_block_12/batch_normalization_26/beta\n",
      "Asignando conv2d_62/kernel a kernel\n",
      "assinging conv2d_62/kernel to sequential_3/residual_block_12/conv2d_31/kernel\n",
      "Asignando conv2d_60/kernel a kernel\n",
      "assinging conv2d_60/kernel to sequential_3/residual_block_12/conv2d_32/kernel\n",
      "Asignando batch_normalization_46/gamma a gamma\n",
      "assinging batch_normalization_46/gamma to sequential_3/residual_block_13/batch_normalization_27/gamma\n",
      "Asignando batch_normalization_46/beta a beta\n",
      "assinging batch_normalization_46/beta to sequential_3/residual_block_13/batch_normalization_27/beta\n",
      "Asignando conv2d_63/kernel a kernel\n",
      "assinging conv2d_63/kernel to sequential_3/residual_block_13/conv2d_33/kernel\n",
      "Asignando batch_normalization_47/gamma a gamma\n",
      "assinging batch_normalization_47/gamma to sequential_3/residual_block_13/batch_normalization_28/gamma\n",
      "Asignando batch_normalization_47/beta a beta\n",
      "assinging batch_normalization_47/beta to sequential_3/residual_block_13/batch_normalization_28/beta\n",
      "Asignando conv2d_64/kernel a kernel\n",
      "assinging conv2d_64/kernel to sequential_3/residual_block_13/conv2d_34/kernel\n",
      "Asignando batch_normalization_48/gamma a gamma\n",
      "assinging batch_normalization_48/gamma to sequential_3/residual_block_14/batch_normalization_29/gamma\n",
      "Asignando batch_normalization_48/beta a beta\n",
      "assinging batch_normalization_48/beta to sequential_3/residual_block_14/batch_normalization_29/beta\n",
      "Asignando conv2d_65/kernel a kernel\n",
      "assinging conv2d_65/kernel to sequential_3/residual_block_14/conv2d_35/kernel\n",
      "Asignando batch_normalization_49/gamma a gamma\n",
      "assinging batch_normalization_49/gamma to sequential_3/residual_block_14/batch_normalization_30/gamma\n",
      "Asignando batch_normalization_49/beta a beta\n",
      "assinging batch_normalization_49/beta to sequential_3/residual_block_14/batch_normalization_30/beta\n",
      "Asignando conv2d_66/kernel a kernel\n",
      "assinging conv2d_66/kernel to sequential_3/residual_block_14/conv2d_36/kernel\n",
      "Asignando batch_normalization_50/gamma a gamma\n",
      "assinging batch_normalization_50/gamma to sequential_3/residual_block_15/batch_normalization_31/gamma\n",
      "Asignando batch_normalization_50/beta a beta\n",
      "assinging batch_normalization_50/beta to sequential_3/residual_block_15/batch_normalization_31/beta\n",
      "Asignando conv2d_68/kernel a kernel\n",
      "assinging conv2d_68/kernel to sequential_3/residual_block_15/conv2d_37/kernel\n",
      "Asignando batch_normalization_51/gamma a gamma\n",
      "assinging batch_normalization_51/gamma to sequential_3/residual_block_15/batch_normalization_32/gamma\n",
      "Asignando batch_normalization_51/beta a beta\n",
      "assinging batch_normalization_51/beta to sequential_3/residual_block_15/batch_normalization_32/beta\n",
      "Asignando conv2d_69/kernel a kernel\n",
      "assinging conv2d_69/kernel to sequential_3/residual_block_15/conv2d_38/kernel\n",
      "Asignando conv2d_67/kernel a kernel\n",
      "assinging conv2d_67/kernel to sequential_3/residual_block_15/conv2d_39/kernel\n",
      "Asignando batch_normalization_52/gamma a gamma\n",
      "assinging batch_normalization_52/gamma to sequential_3/residual_block_16/batch_normalization_33/gamma\n",
      "Asignando batch_normalization_52/beta a beta\n",
      "assinging batch_normalization_52/beta to sequential_3/residual_block_16/batch_normalization_33/beta\n",
      "Asignando conv2d_70/kernel a kernel\n",
      "assinging conv2d_70/kernel to sequential_3/residual_block_16/conv2d_40/kernel\n",
      "Asignando batch_normalization_53/gamma a gamma\n",
      "assinging batch_normalization_53/gamma to sequential_3/residual_block_16/batch_normalization_34/gamma\n",
      "Asignando batch_normalization_53/beta a beta\n",
      "assinging batch_normalization_53/beta to sequential_3/residual_block_16/batch_normalization_34/beta\n",
      "Asignando conv2d_71/kernel a kernel\n",
      "assinging conv2d_71/kernel to sequential_3/residual_block_16/conv2d_41/kernel\n",
      "Asignando batch_normalization_54/gamma a gamma\n",
      "assinging batch_normalization_54/gamma to sequential_3/residual_block_17/batch_normalization_35/gamma\n",
      "Asignando batch_normalization_54/beta a beta\n",
      "assinging batch_normalization_54/beta to sequential_3/residual_block_17/batch_normalization_35/beta\n",
      "Asignando conv2d_72/kernel a kernel\n",
      "assinging conv2d_72/kernel to sequential_3/residual_block_17/conv2d_42/kernel\n",
      "Asignando batch_normalization_55/gamma a gamma\n",
      "assinging batch_normalization_55/gamma to sequential_3/residual_block_17/batch_normalization_36/gamma\n",
      "Asignando batch_normalization_55/beta a beta\n",
      "assinging batch_normalization_55/beta to sequential_3/residual_block_17/batch_normalization_36/beta\n",
      "Asignando conv2d_73/kernel a kernel\n",
      "assinging conv2d_73/kernel to sequential_3/residual_block_17/conv2d_43/kernel\n",
      "Asignando batch_normalization_56/gamma a gamma\n",
      "assinging batch_normalization_56/gamma to sequential_3/batch_normalization_37/gamma\n",
      "Asignando batch_normalization_56/beta a beta\n",
      "assinging batch_normalization_56/beta to sequential_3/batch_normalization_37/beta\n",
      "Asignando dense_2/kernel a kernel\n",
      "assinging dense_2/kernel to sequential_3/dense_1/kernel\n",
      "Asignando dense_2/bias a bias\n",
      "assinging dense_2/bias to sequential_3/dense_1/bias\n",
      "Asignando batch_normalization_38/moving_mean a moving_mean\n",
      "assinging batch_normalization_38/moving_mean to sequential_3/residual_block_9/batch_normalization_19/moving_mean\n",
      "Asignando batch_normalization_38/moving_variance a moving_variance\n",
      "assinging batch_normalization_38/moving_variance to sequential_3/residual_block_9/batch_normalization_19/moving_variance\n",
      "Asignando batch_normalization_39/moving_mean a moving_mean\n",
      "assinging batch_normalization_39/moving_mean to sequential_3/residual_block_9/batch_normalization_20/moving_mean\n",
      "Asignando batch_normalization_39/moving_variance a moving_variance\n",
      "assinging batch_normalization_39/moving_variance to sequential_3/residual_block_9/batch_normalization_20/moving_variance\n",
      "Asignando batch_normalization_40/moving_mean a moving_mean\n",
      "assinging batch_normalization_40/moving_mean to sequential_3/residual_block_10/batch_normalization_21/moving_mean\n",
      "Asignando batch_normalization_40/moving_variance a moving_variance\n",
      "assinging batch_normalization_40/moving_variance to sequential_3/residual_block_10/batch_normalization_21/moving_variance\n",
      "Asignando batch_normalization_41/moving_mean a moving_mean\n",
      "assinging batch_normalization_41/moving_mean to sequential_3/residual_block_10/batch_normalization_22/moving_mean\n",
      "Asignando batch_normalization_41/moving_variance a moving_variance\n",
      "assinging batch_normalization_41/moving_variance to sequential_3/residual_block_10/batch_normalization_22/moving_variance\n",
      "Asignando batch_normalization_42/moving_mean a moving_mean\n",
      "assinging batch_normalization_42/moving_mean to sequential_3/residual_block_11/batch_normalization_23/moving_mean\n",
      "Asignando batch_normalization_42/moving_variance a moving_variance\n",
      "assinging batch_normalization_42/moving_variance to sequential_3/residual_block_11/batch_normalization_23/moving_variance\n",
      "Asignando batch_normalization_43/moving_mean a moving_mean\n",
      "assinging batch_normalization_43/moving_mean to sequential_3/residual_block_11/batch_normalization_24/moving_mean\n",
      "Asignando batch_normalization_43/moving_variance a moving_variance\n",
      "assinging batch_normalization_43/moving_variance to sequential_3/residual_block_11/batch_normalization_24/moving_variance\n",
      "Asignando batch_normalization_44/moving_mean a moving_mean\n",
      "assinging batch_normalization_44/moving_mean to sequential_3/residual_block_12/batch_normalization_25/moving_mean\n",
      "Asignando batch_normalization_44/moving_variance a moving_variance\n",
      "assinging batch_normalization_44/moving_variance to sequential_3/residual_block_12/batch_normalization_25/moving_variance\n",
      "Asignando batch_normalization_45/moving_mean a moving_mean\n",
      "assinging batch_normalization_45/moving_mean to sequential_3/residual_block_12/batch_normalization_26/moving_mean\n",
      "Asignando batch_normalization_45/moving_variance a moving_variance\n",
      "assinging batch_normalization_45/moving_variance to sequential_3/residual_block_12/batch_normalization_26/moving_variance\n",
      "Asignando batch_normalization_46/moving_mean a moving_mean\n",
      "assinging batch_normalization_46/moving_mean to sequential_3/residual_block_13/batch_normalization_27/moving_mean\n",
      "Asignando batch_normalization_46/moving_variance a moving_variance\n",
      "assinging batch_normalization_46/moving_variance to sequential_3/residual_block_13/batch_normalization_27/moving_variance\n",
      "Asignando batch_normalization_47/moving_mean a moving_mean\n",
      "assinging batch_normalization_47/moving_mean to sequential_3/residual_block_13/batch_normalization_28/moving_mean\n",
      "Asignando batch_normalization_47/moving_variance a moving_variance\n",
      "assinging batch_normalization_47/moving_variance to sequential_3/residual_block_13/batch_normalization_28/moving_variance\n",
      "Asignando batch_normalization_48/moving_mean a moving_mean\n",
      "assinging batch_normalization_48/moving_mean to sequential_3/residual_block_14/batch_normalization_29/moving_mean\n",
      "Asignando batch_normalization_48/moving_variance a moving_variance\n",
      "assinging batch_normalization_48/moving_variance to sequential_3/residual_block_14/batch_normalization_29/moving_variance\n",
      "Asignando batch_normalization_49/moving_mean a moving_mean\n",
      "assinging batch_normalization_49/moving_mean to sequential_3/residual_block_14/batch_normalization_30/moving_mean\n",
      "Asignando batch_normalization_49/moving_variance a moving_variance\n",
      "assinging batch_normalization_49/moving_variance to sequential_3/residual_block_14/batch_normalization_30/moving_variance\n",
      "Asignando batch_normalization_50/moving_mean a moving_mean\n",
      "assinging batch_normalization_50/moving_mean to sequential_3/residual_block_15/batch_normalization_31/moving_mean\n",
      "Asignando batch_normalization_50/moving_variance a moving_variance\n",
      "assinging batch_normalization_50/moving_variance to sequential_3/residual_block_15/batch_normalization_31/moving_variance\n",
      "Asignando batch_normalization_51/moving_mean a moving_mean\n",
      "assinging batch_normalization_51/moving_mean to sequential_3/residual_block_15/batch_normalization_32/moving_mean\n",
      "Asignando batch_normalization_51/moving_variance a moving_variance\n",
      "assinging batch_normalization_51/moving_variance to sequential_3/residual_block_15/batch_normalization_32/moving_variance\n",
      "Asignando batch_normalization_52/moving_mean a moving_mean\n",
      "assinging batch_normalization_52/moving_mean to sequential_3/residual_block_16/batch_normalization_33/moving_mean\n",
      "Asignando batch_normalization_52/moving_variance a moving_variance\n",
      "assinging batch_normalization_52/moving_variance to sequential_3/residual_block_16/batch_normalization_33/moving_variance\n",
      "Asignando batch_normalization_53/moving_mean a moving_mean\n",
      "assinging batch_normalization_53/moving_mean to sequential_3/residual_block_16/batch_normalization_34/moving_mean\n",
      "Asignando batch_normalization_53/moving_variance a moving_variance\n",
      "assinging batch_normalization_53/moving_variance to sequential_3/residual_block_16/batch_normalization_34/moving_variance\n",
      "Asignando batch_normalization_54/moving_mean a moving_mean\n",
      "assinging batch_normalization_54/moving_mean to sequential_3/residual_block_17/batch_normalization_35/moving_mean\n",
      "Asignando batch_normalization_54/moving_variance a moving_variance\n",
      "assinging batch_normalization_54/moving_variance to sequential_3/residual_block_17/batch_normalization_35/moving_variance\n",
      "Asignando batch_normalization_55/moving_mean a moving_mean\n",
      "assinging batch_normalization_55/moving_mean to sequential_3/residual_block_17/batch_normalization_36/moving_mean\n",
      "Asignando batch_normalization_55/moving_variance a moving_variance\n",
      "assinging batch_normalization_55/moving_variance to sequential_3/residual_block_17/batch_normalization_36/moving_variance\n",
      "Asignando batch_normalization_56/moving_mean a moving_mean\n",
      "assinging batch_normalization_56/moving_mean to sequential_3/batch_normalization_37/moving_mean\n",
      "Asignando batch_normalization_56/moving_variance a moving_variance\n",
      "assinging batch_normalization_56/moving_variance to sequential_3/batch_normalization_37/moving_variance\n",
      "313/313 - 4s - 12ms/step - accuracy: 0.7029 - loss: 1.0759\n",
      "Precisión en el conjunto de prueba: 70.29%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100, cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "# Cargar CIFAR-100\n",
    "(x_train_100, y_train_100), (x_test_100, y_test_100) = cifar100.load_data()\n",
    "\n",
    "# Normalizar las imágenes a [-1, 1]\n",
    "x_train_100 = (x_train_100 / 127.5) - 1  # Escalar a [-1, 1]\n",
    "x_test_100 = (x_test_100 / 127.5) - 1   # Escalar a [-1, 1]\n",
    "\n",
    "# Convertir las etiquetas a formato one-hot\n",
    "y_train_100 = to_categorical(y_train_100, 100)  # 100 clases en CIFAR-100\n",
    "y_test_100 = to_categorical(y_test_100, 100)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Ruta del archivo de pesos\n",
    "path_to_weights = \"/kaggle/input/pickel/p3_model_weights.pkl\"\n",
    "# path_to_weights = os.path.join(\".\", \"p3\n",
    "#_model_weights.pkl\")\n",
    "# Cargar los pesos en el modelo usando la función `load_weights`\n",
    "load_weights(model, path_to_weights)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(x_test_100, y_test_100, verbose=2)\n",
    "\n",
    "# Mostrar la precisión\n",
    "print(f\"Precisión en el conjunto de prueba: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3\n",
    "##### Entrenamos mediante la técnica de fine-tuning, sobre el dataset CIFAR-10, manteniendo fijos los pesos de la red preentrenada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos declarado data augmentation como un modelo de keras que rotará las imagenes horizontalmente, le aplicará una pequeña rotación aleatoria y un zoom aleatorio. Si hemos puesto esto, y no hemos añadido cosas extra como una rotación vertical, es porque a la hora de modificar las imagenes creadas, hemos buscado que sigan siendo coherentes con los datos a entrenar (no tiene sentido que  el modelo entrene con un avión boca abajo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:34:58.361303Z",
     "iopub.status.busy": "2024-11-29T21:34:58.360705Z",
     "iopub.status.idle": "2024-11-29T21:34:59.792286Z",
     "shell.execute_reply": "2024-11-29T21:34:59.791590Z",
     "shell.execute_reply.started": "2024-11-29T21:34:58.361267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation \n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Cargar el conjunto de datos CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalizar las imágenes a rango [-1, 1]\n",
    "x_train = (x_train / 127.5) - 1\n",
    "x_test = (x_test / 127.5) - 1 \n",
    "\n",
    "# Convertir las etiquetas a formato one-hot\n",
    "y_train = to_categorical(y_train, 10)  # 10 clases en CIFAR-10\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar hemos realizado un modelo empleando el método fit para comprobar que el bucle desde cero está implementado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:35:01.020817Z",
     "iopub.status.busy": "2024-11-29T21:35:01.019993Z",
     "iopub.status.idle": "2024-11-29T21:37:20.429493Z",
     "shell.execute_reply": "2024-11-29T21:37:20.428661Z",
     "shell.execute_reply.started": "2024-11-29T21:35:01.020781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,424</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">919,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">77,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m47,424\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m230,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m919,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m77,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m60,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m20,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,460,218</span> (17.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,460,218\u001b[0m (17.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,410</span> (618.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m158,410\u001b[0m (618.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,301,808</span> (16.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,301,808\u001b[0m (16.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_22 -> Frozen\n",
      "residual_block_9 -> Frozen\n",
      "residual_block_10 -> Frozen\n",
      "residual_block_11 -> Frozen\n",
      "residual_block_12 -> Frozen\n",
      "residual_block_13 -> Frozen\n",
      "residual_block_14 -> Frozen\n",
      "residual_block_15 -> Frozen\n",
      "residual_block_16 -> Frozen\n",
      "residual_block_17 -> Frozen\n",
      "batch_normalization_37 -> Frozen\n",
      "activation_37 -> Frozen\n",
      "global_average_pooling2d_1 -> Frozen\n",
      "dense_2 -> Trainable: True, Neurons: 300\n",
      "dense_3 -> Trainable: True, Neurons: 200\n",
      "dense_4 -> Trainable: True, Neurons: 100\n",
      "dense_5 -> Trainable: True, Neurons: 10\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.6060 - loss: 1.0957\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6878 - loss: 0.8757\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7075 - loss: 0.8214\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7203 - loss: 0.7948\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7275 - loss: 0.7764\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7324 - loss: 0.7573\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7364 - loss: 0.7436\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7408 - loss: 0.7316\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7437 - loss: 0.7151\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7511 - loss: 0.7003\n",
      "313/313 - 4s - 12ms/step - accuracy: 0.7744 - loss: 0.6597\n",
      "Precisión en el conjunto de prueba: 77.44%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear un Dataset de TensorFlow para aplicar el Data Augmentation de manera eficiente\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(5000).batch(32).map(lambda x, y: (data_augmentation(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Test dataset (sin augmentation)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Congelar todas las capas\n",
    "model.trainable = False\n",
    "# Descongelar solo la última capa densa\n",
    "model.layers[-1].trainable = True  # Descongelar la capa Dense(100)\n",
    "\n",
    "# Crear una nueva lista de capas, excluyendo la última\n",
    "model_layers = model.layers[:-1]  # Esto elimina la última capa\n",
    "\n",
    "# Crear un nuevo modelo con las capas restantes\n",
    "new_model = models.Sequential(model_layers)\n",
    "# Añadir una nueva capa Dense con 10 neuronas para CIFAR-10\n",
    "new_model.add(layers.Dense(300, activation='swish'))\n",
    "new_model.add(layers.Dense(200, activation='swish'))\n",
    "new_model.add(layers.Dense(100, activation='swish'))\n",
    "new_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Resumen del nuevo modelo\n",
    "new_model.summary()\n",
    "\n",
    "# Verificamos las capas congeladas \n",
    "for layer in new_model.layers:\n",
    "    if isinstance(layer, layers.Dense):  # Si la capa es una capa densa\n",
    "        print(f\"{layer.name} -> Trainable: {layer.trainable}, Neurons: {layer.units}\")\n",
    "    else:\n",
    "        print(f\"{layer.name} -> {'Trainable' if layer.trainable else 'Frozen'}\")\n",
    "\n",
    "# Compilar el modelo nuevamente \n",
    "new_model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento con datos de entrenamiento y Data Augmentation aplicado\n",
    "new_model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = new_model.evaluate(test_dataset, verbose=2)\n",
    "\n",
    "# Mostrar la precisión\n",
    "print(f\"Precisión en el conjunto de prueba: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el bucle de entrenamiento eficiente, primero hemos creado dos modelos separados: frozen_model; siendo el modelo preentrenado original sin la última capa que permanecerá intacto y trainable_model;  que es el modelo que será entrenado en el bucle.\n",
    "Hemos decidido separarlos en 2, porque así a la hora de calcular el gradiente, si solo le pasamos el modelo entrenable (pero con los inputs siendo procesados por el modelo congelado), ahorramos que calcule un gradiente y mantenga en memoria al modelo que no debe alterar en ningún momento (mayor eficiencia computacional y espacial). También hemos realizado la evalución manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:39:19.592957Z",
     "iopub.status.busy": "2024-11-29T21:39:19.592126Z",
     "iopub.status.idle": "2024-11-29T21:46:56.123277Z",
     "shell.execute_reply": "2024-11-29T21:46:56.122423Z",
     "shell.execute_reply.started": "2024-11-29T21:39:19.592926Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Step 0: Loss = 2.3177, Accuracy = 0.0547\n",
      "Step 100: Loss = 0.9445, Accuracy = 0.5685\n",
      "Step 200: Loss = 1.0307, Accuracy = 0.6107\n",
      "Step 300: Loss = 0.9692, Accuracy = 0.6281\n",
      "Epoch 1: Loss = 1.0114, Accuracy = 0.6383\n",
      "Epoch 2/10\n",
      "Step 0: Loss = 0.8670, Accuracy = 0.6719\n",
      "Step 100: Loss = 0.9485, Accuracy = 0.6794\n",
      "Step 200: Loss = 0.7051, Accuracy = 0.6864\n",
      "Step 300: Loss = 1.0275, Accuracy = 0.6867\n",
      "Epoch 2: Loss = 0.8683, Accuracy = 0.6888\n",
      "Epoch 3/10\n",
      "Step 0: Loss = 0.7350, Accuracy = 0.7734\n",
      "Step 100: Loss = 0.8232, Accuracy = 0.7044\n",
      "Step 200: Loss = 0.8198, Accuracy = 0.7055\n",
      "Step 300: Loss = 0.6871, Accuracy = 0.7047\n",
      "Epoch 3: Loss = 0.8234, Accuracy = 0.7050\n",
      "Epoch 4/10\n",
      "Step 0: Loss = 0.7179, Accuracy = 0.7344\n",
      "Step 100: Loss = 0.7417, Accuracy = 0.7150\n",
      "Step 200: Loss = 0.8147, Accuracy = 0.7149\n",
      "Step 300: Loss = 0.6927, Accuracy = 0.7149\n",
      "Epoch 4: Loss = 0.7980, Accuracy = 0.7153\n",
      "Epoch 5/10\n",
      "Step 0: Loss = 0.8614, Accuracy = 0.6797\n",
      "Step 100: Loss = 0.8125, Accuracy = 0.7267\n",
      "Step 200: Loss = 0.7654, Accuracy = 0.7258\n",
      "Step 300: Loss = 0.7324, Accuracy = 0.7262\n",
      "Epoch 5: Loss = 0.7718, Accuracy = 0.7251\n",
      "Epoch 6/10\n",
      "Step 0: Loss = 0.7833, Accuracy = 0.7344\n",
      "Step 100: Loss = 0.7977, Accuracy = 0.7270\n",
      "Step 200: Loss = 0.7897, Accuracy = 0.7273\n",
      "Step 300: Loss = 0.8724, Accuracy = 0.7285\n",
      "Epoch 6: Loss = 0.7550, Accuracy = 0.7298\n",
      "Epoch 7/10\n",
      "Step 0: Loss = 0.6783, Accuracy = 0.7812\n",
      "Step 100: Loss = 0.7437, Accuracy = 0.7393\n",
      "Step 200: Loss = 0.7087, Accuracy = 0.7383\n",
      "Step 300: Loss = 0.8687, Accuracy = 0.7369\n",
      "Epoch 7: Loss = 0.7325, Accuracy = 0.7374\n",
      "Epoch 8/10\n",
      "Step 0: Loss = 0.8615, Accuracy = 0.7109\n",
      "Step 100: Loss = 0.7842, Accuracy = 0.7413\n",
      "Step 200: Loss = 0.6211, Accuracy = 0.7420\n",
      "Step 300: Loss = 0.6069, Accuracy = 0.7443\n",
      "Epoch 8: Loss = 0.7218, Accuracy = 0.7430\n",
      "Epoch 9/10\n",
      "Step 0: Loss = 0.8069, Accuracy = 0.6953\n",
      "Step 100: Loss = 0.5365, Accuracy = 0.7490\n",
      "Step 200: Loss = 0.5155, Accuracy = 0.7483\n",
      "Step 300: Loss = 0.6586, Accuracy = 0.7480\n",
      "Epoch 9: Loss = 0.7067, Accuracy = 0.7487\n",
      "Epoch 10/10\n",
      "Step 0: Loss = 0.6706, Accuracy = 0.7266\n",
      "Step 100: Loss = 0.5953, Accuracy = 0.7581\n",
      "Step 200: Loss = 0.7302, Accuracy = 0.7544\n",
      "Step 300: Loss = 0.6963, Accuracy = 0.7542\n",
      "Epoch 10: Loss = 0.6923, Accuracy = 0.7531\n",
      "Test Loss = 0.6628, Test Accuracy = 0.7655\n"
     ]
    }
   ],
   "source": [
    "# Dividir el modelo en dos partes\n",
    "frozen_model = Sequential(model.layers[:-1])  # Todas las capas excepto la última\n",
    "\n",
    "frozen_model.trainable = False  # Congelar las capas\n",
    "\n",
    "trainable_model = Sequential([\n",
    "    layers.Dense(300, activation='swish'),  # Capa densa adicional\n",
    "    layers.Dense(200, activation='swish'),  # Capa densa adicional\n",
    "    layers.Dense(100, activation='swish'),  # Capa densa adicional\n",
    "    layers.Dense(10, activation='softmax')  # Salida para CIFAR-10\n",
    "])\n",
    "\n",
    "# Configurar parámetros de entrenamiento\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "# Crear dataset de entrenamiento con data augmentation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Dataset de prueba (sin augmentación)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Bucle de entrenamiento manual\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_dataset):\n",
    "        # Data augmentation\n",
    "        augmented_images = data_augmentation(images)\n",
    "        frozen_output = frozen_model(augmented_images, training=False)  # Bloque congelado\n",
    "\n",
    "        # Forward pass y cálculo de gradientes\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = trainable_model(frozen_output, training=True)  # Bloque entrenable\n",
    "            loss = loss_function(labels, predictions)\n",
    "\n",
    "        # Backward pass: calcular y aplicar gradientes solo a las capas entrenables\n",
    "        gradients = tape.gradient(loss, trainable_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_model.trainable_variables))\n",
    "\n",
    "        # Actualizar métricas\n",
    "        epoch_loss += loss.numpy()\n",
    "        epoch_accuracy.update_state(labels, predictions)\n",
    "\n",
    "        # Imprimir progreso\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Loss = {loss.numpy():.4f}, Accuracy = {epoch_accuracy.result().numpy():.4f}\")\n",
    "\n",
    "    # Imprimir métricas por época\n",
    "    print(f\"Epoch {epoch + 1}: Loss = {epoch_loss / len(train_dataset):.4f}, Accuracy = {epoch_accuracy.result().numpy():.4f}\")\n",
    "\n",
    "# Evaluación final en el conjunto de prueba\n",
    "test_loss, test_accuracy = 0, tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    frozen_output = frozen_model(images, training=False)\n",
    "    predictions = trainable_model(frozen_output, training=False)\n",
    "    test_loss += loss_function(labels, predictions).numpy()\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "\n",
    "print(f\"Test Loss = {test_loss / len(test_dataset):.4f}, Test Accuracy = {test_accuracy.result().numpy():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del resultado del conjunto de test.\n",
    "\n",
    "El modelo entrenado muestra un rendimiento sólido, con una precisión de test del 76.55% y una pérdida de test de 0.6628, lo que indica una buena capacidad de generalización. Durante el entrenamiento, la precisión aumentó de 5.47% a 75,31%, mientras que la pérdida disminuyó progresivamente desde 2.31 hasta 0.6923, lo que refleja una mejora constante en el aprendizaje. La pequeña diferencia entre las métricas de entrenamiento y test sugiere que el modelo no está sobreajustado, ya que la precisión en el conjunto de test es incluso mayor que en el de entrenamiento. Este comportamiento muestra que el modelo ha aprendido los patrones del conjunto de datos sin memorizar, lo cual es una señal de buena generalización. Sin embargo, se podrían explorar más épocas o técnicas de regularización para mejorar aún más el rendimiento. En general, el modelo ha alcanzado un buen nivel de desempeño en pocas épocas de entrenamiento.\n",
    "\n",
    "Por último, podemos comprobar que empleando fit y el bucle, los resultados son similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4\n",
    "Entrenamos la red por fine tunning pero sin mantener fijos los pesos de la red preentrenada.\n",
    "\n",
    "En primer lugar hemos realizado un modelo empleando el método fit para comprobar que el bucle desde cero está implementado correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T22:33:54.026428Z",
     "iopub.status.busy": "2024-11-29T22:33:54.026072Z",
     "iopub.status.idle": "2024-11-29T22:36:43.158806Z",
     "shell.execute_reply": "2024-11-29T22:36:43.157875Z",
     "shell.execute_reply.started": "2024-11-29T22:33:54.026394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,424</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">919,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m47,424\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m230,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m919,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,304,378</span> (16.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,304,378\u001b[0m (16.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,293,562</span> (16.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,293,562\u001b[0m (16.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,816</span> (42.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,816\u001b[0m (42.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_22 -> Trainable\n",
      "ResidualBlock: residual_block_9\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_10\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_11\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_12\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_13\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_14\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_15\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_16\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "ResidualBlock: residual_block_17\n",
      "  BatchNormalization bn1 -> Trainable: False\n",
      "  BatchNormalization bn2 -> Trainable: False\n",
      "batch_normalization_37 -> Frozen\n",
      "activation_37 -> Trainable\n",
      "global_average_pooling2d_1 -> Trainable\n",
      "dense_23 -> Trainable: True, Neurons: 10\n",
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 60ms/step - accuracy: 0.6113 - loss: 1.7374\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9427 - loss: 0.1760\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9683 - loss: 0.1017\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9781 - loss: 0.0744\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9839 - loss: 0.0572\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9887 - loss: 0.0449\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.9908 - loss: 0.0383\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9931 - loss: 0.0321\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9956 - loss: 0.0274\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9962 - loss: 0.0232\n",
      "79/79 - 3s - 35ms/step - accuracy: 0.8811 - loss: 0.5083\n",
      "Precisión en el conjunto de prueba: 88.11%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.trainable = True\n",
    "\n",
    "# Congelar solo las capas de BatchNormalization\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False \n",
    "    elif isinstance(layer, ResidualBlock):\n",
    "        if isinstance(layer.bn1, layers.BatchNormalization):\n",
    "            layer.bn1.trainable = False\n",
    "        if isinstance(layer.bn2, layers.BatchNormalization):\n",
    "            layer.bn2.trainable = False\n",
    "        \n",
    "# Crear una nueva lista de capas, excluyendo la última\n",
    "model_layers = model.layers[:-1]  # Esto elimina la última capa\n",
    "\n",
    "# Crear un nuevo modelo con las capas restantes\n",
    "new_model = models.Sequential(model_layers)\n",
    "\n",
    "# Añadir una nueva capa Dense con 10 neuronas para CIFAR-10\n",
    "new_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Resumen del nuevo modelo\n",
    "new_model.summary()\n",
    "\n",
    "# Verificamos las capas congeladas \n",
    "for layer in new_model.layers:\n",
    "    if isinstance(layer, layers.Dense):  # Si la capa es una capa densa\n",
    "        print(f\"{layer.name} -> Trainable: {layer.trainable}, Neurons: {layer.units}\")\n",
    "    elif isinstance(layer, ResidualBlock):\n",
    "        print(f\"ResidualBlock: {layer.name}\")\n",
    "        if isinstance(layer.bn1, layers.BatchNormalization):\n",
    "            print(f\"  BatchNormalization bn1 -> Trainable: {layer.bn1.trainable}\")\n",
    "        if isinstance(layer.bn2, layers.BatchNormalization):\n",
    "            print(f\"  BatchNormalization bn2 -> Trainable: {layer.bn2.trainable}\")\n",
    "    else:\n",
    "        print(f\"{layer.name} -> {'Trainable' if layer.trainable else 'Frozen'}\")\n",
    "\n",
    "\n",
    "# Compilar el modelo nuevamente\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9, learning_rate=0.0001 )\n",
    "new_model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento con datos reales\n",
    "history = new_model.fit(train_dataset, batch_size=32, epochs= 10)\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = new_model.evaluate(test_dataset, verbose=2)\n",
    "\n",
    "# Mostrar la precisión\n",
    "print(f\"Precisión en el conjunto de prueba: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, hemos congelado las capas internas de batch normalization de los bloques residuales y además hemos hecho un único modelo para pasárselo al bucle, ya que no hace falta optimizarlo como en la parte 3, porque vamos a entrenarlo todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T21:58:11.743751Z",
     "iopub.status.busy": "2024-11-29T21:58:11.743064Z",
     "iopub.status.idle": "2024-11-29T22:15:51.747612Z",
     "shell.execute_reply": "2024-11-29T22:15:51.746762Z",
     "shell.execute_reply.started": "2024-11-29T21:58:11.743714Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,424</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">919,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m47,424\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m230,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,936\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m919,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,304,378</span> (16.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,304,378\u001b[0m (16.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,293,562</span> (16.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,293,562\u001b[0m (16.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,816</span> (42.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,816\u001b[0m (42.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Step 0: Loss = 3.7830, Accuracy = 0.2500\n",
      "Step 100: Loss = 0.7793, Accuracy = 0.5370\n",
      "Step 200: Loss = 0.6642, Accuracy = 0.6265\n",
      "Step 300: Loss = 0.7204, Accuracy = 0.6662\n",
      "Epoch 1: Loss = 0.8648, Accuracy = 0.6693\n",
      "\n",
      "Epoch 2/20\n",
      "Step 0: Loss = 0.7137, Accuracy = 0.7500\n",
      "Step 100: Loss = 0.7548, Accuracy = 0.7616\n",
      "Step 200: Loss = 0.4949, Accuracy = 0.7668\n",
      "Step 300: Loss = 0.5391, Accuracy = 0.7723\n",
      "Epoch 2: Loss = 0.8648, Accuracy = 0.7728\n",
      "\n",
      "Epoch 3/20\n",
      "Step 0: Loss = 0.6298, Accuracy = 0.7500\n",
      "Step 100: Loss = 0.6039, Accuracy = 0.7894\n",
      "Step 200: Loss = 0.6176, Accuracy = 0.7926\n",
      "Step 300: Loss = 0.5615, Accuracy = 0.7939\n",
      "Epoch 3: Loss = 0.8648, Accuracy = 0.7939\n",
      "\n",
      "Epoch 4/20\n",
      "Step 0: Loss = 0.6469, Accuracy = 0.7812\n",
      "Step 100: Loss = 0.4725, Accuracy = 0.7986\n",
      "Step 200: Loss = 0.5330, Accuracy = 0.7999\n",
      "Step 300: Loss = 0.5106, Accuracy = 0.8021\n",
      "Epoch 4: Loss = 0.8648, Accuracy = 0.8019\n",
      "\n",
      "Epoch 5/20\n",
      "Step 0: Loss = 0.5227, Accuracy = 0.8281\n",
      "Step 100: Loss = 0.5128, Accuracy = 0.8069\n",
      "Step 200: Loss = 0.6940, Accuracy = 0.8062\n",
      "Step 300: Loss = 0.4578, Accuracy = 0.8080\n",
      "Epoch 5: Loss = 0.8648, Accuracy = 0.8074\n",
      "\n",
      "Epoch 6/20\n",
      "Step 0: Loss = 0.6614, Accuracy = 0.7422\n",
      "Step 100: Loss = 0.4847, Accuracy = 0.8110\n",
      "Step 200: Loss = 0.5931, Accuracy = 0.8127\n",
      "Step 300: Loss = 0.4999, Accuracy = 0.8122\n",
      "Epoch 6: Loss = 0.8648, Accuracy = 0.8124\n",
      "\n",
      "Epoch 7/20\n",
      "Step 0: Loss = 0.6090, Accuracy = 0.7578\n",
      "Step 100: Loss = 0.6248, Accuracy = 0.8126\n",
      "Step 200: Loss = 0.5096, Accuracy = 0.8166\n",
      "Step 300: Loss = 0.5703, Accuracy = 0.8167\n",
      "Epoch 7: Loss = 0.8648, Accuracy = 0.8163\n",
      "\n",
      "Epoch 8/20\n",
      "Step 0: Loss = 0.4462, Accuracy = 0.8203\n",
      "Step 100: Loss = 0.5088, Accuracy = 0.8229\n",
      "Step 200: Loss = 0.4145, Accuracy = 0.8224\n",
      "Step 300: Loss = 0.4432, Accuracy = 0.8235\n",
      "Epoch 8: Loss = 0.8648, Accuracy = 0.8239\n",
      "\n",
      "Epoch 9/20\n",
      "Step 0: Loss = 0.5840, Accuracy = 0.7969\n",
      "Step 100: Loss = 0.5343, Accuracy = 0.8203\n",
      "Step 200: Loss = 0.5028, Accuracy = 0.8237\n",
      "Step 300: Loss = 0.4573, Accuracy = 0.8244\n",
      "Epoch 9: Loss = 0.8648, Accuracy = 0.8241\n",
      "\n",
      "Epoch 10/20\n",
      "Step 0: Loss = 0.6909, Accuracy = 0.7422\n",
      "Step 100: Loss = 0.4683, Accuracy = 0.8223\n",
      "Step 200: Loss = 0.5135, Accuracy = 0.8256\n",
      "Step 300: Loss = 0.6591, Accuracy = 0.8240\n",
      "Epoch 10: Loss = 0.8648, Accuracy = 0.8244\n",
      "\n",
      "Epoch 11/20\n",
      "Step 0: Loss = 0.4374, Accuracy = 0.8438\n",
      "Step 100: Loss = 0.5024, Accuracy = 0.8234\n",
      "Step 200: Loss = 0.5251, Accuracy = 0.8260\n",
      "Step 300: Loss = 0.4467, Accuracy = 0.8270\n",
      "Epoch 11: Loss = 0.8648, Accuracy = 0.8268\n",
      "\n",
      "Epoch 12/20\n",
      "Step 0: Loss = 0.6247, Accuracy = 0.7969\n",
      "Step 100: Loss = 0.5261, Accuracy = 0.8342\n",
      "Step 200: Loss = 0.3612, Accuracy = 0.8343\n",
      "Step 300: Loss = 0.4356, Accuracy = 0.8320\n",
      "Epoch 12: Loss = 0.8648, Accuracy = 0.8321\n",
      "\n",
      "Epoch 13/20\n",
      "Step 0: Loss = 0.5629, Accuracy = 0.8125\n",
      "Step 100: Loss = 0.4734, Accuracy = 0.8273\n",
      "Step 200: Loss = 0.5183, Accuracy = 0.8282\n",
      "Step 300: Loss = 0.4004, Accuracy = 0.8302\n",
      "Epoch 13: Loss = 0.8648, Accuracy = 0.8305\n",
      "\n",
      "Epoch 14/20\n",
      "Step 0: Loss = 0.4587, Accuracy = 0.8516\n",
      "Step 100: Loss = 0.3077, Accuracy = 0.8352\n",
      "Step 200: Loss = 0.5800, Accuracy = 0.8376\n",
      "Step 300: Loss = 0.5195, Accuracy = 0.8378\n",
      "Epoch 14: Loss = 0.8648, Accuracy = 0.8373\n",
      "\n",
      "Epoch 15/20\n",
      "Step 0: Loss = 0.4537, Accuracy = 0.8359\n",
      "Step 100: Loss = 0.4567, Accuracy = 0.8365\n",
      "Step 200: Loss = 0.5215, Accuracy = 0.8347\n",
      "Step 300: Loss = 0.5564, Accuracy = 0.8358\n",
      "Epoch 15: Loss = 0.8648, Accuracy = 0.8360\n",
      "\n",
      "Epoch 16/20\n",
      "Step 0: Loss = 0.6735, Accuracy = 0.7500\n",
      "Step 100: Loss = 0.3860, Accuracy = 0.8391\n",
      "Step 200: Loss = 0.4302, Accuracy = 0.8386\n",
      "Step 300: Loss = 0.4460, Accuracy = 0.8372\n",
      "Epoch 16: Loss = 0.8648, Accuracy = 0.8372\n",
      "\n",
      "Epoch 17/20\n",
      "Step 0: Loss = 0.4753, Accuracy = 0.8359\n",
      "Step 100: Loss = 0.5368, Accuracy = 0.8386\n",
      "Step 200: Loss = 0.4390, Accuracy = 0.8398\n",
      "Step 300: Loss = 0.3883, Accuracy = 0.8399\n",
      "Epoch 17: Loss = 0.8648, Accuracy = 0.8403\n",
      "\n",
      "Epoch 18/20\n",
      "Step 0: Loss = 0.4233, Accuracy = 0.8516\n",
      "Step 100: Loss = 0.4635, Accuracy = 0.8438\n",
      "Step 200: Loss = 0.5454, Accuracy = 0.8418\n",
      "Step 300: Loss = 0.3519, Accuracy = 0.8415\n",
      "Epoch 18: Loss = 0.8648, Accuracy = 0.8414\n",
      "\n",
      "Epoch 19/20\n",
      "Step 0: Loss = 0.4187, Accuracy = 0.8516\n",
      "Step 100: Loss = 0.3019, Accuracy = 0.8405\n",
      "Step 200: Loss = 0.4404, Accuracy = 0.8446\n",
      "Step 300: Loss = 0.3744, Accuracy = 0.8441\n",
      "Epoch 19: Loss = 0.8648, Accuracy = 0.8446\n",
      "\n",
      "Epoch 20/20\n",
      "Step 0: Loss = 0.4599, Accuracy = 0.8672\n",
      "Step 100: Loss = 0.3839, Accuracy = 0.8458\n",
      "Step 200: Loss = 0.2616, Accuracy = 0.8487\n",
      "Step 300: Loss = 0.4496, Accuracy = 0.8483\n",
      "Epoch 20: Loss = 0.8648, Accuracy = 0.8486\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8582 - loss: 0.4065\n",
      "Test Loss = 0.4064, Test Accuracy = 0.8599\n"
     ]
    }
   ],
   "source": [
    "model.trainable = True\n",
    "\n",
    "# Congelar las capas de BatchNormalization (ya lo tienes implementado correctamente)\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False  # Congelar la capa\n",
    "    elif isinstance(layer, ResidualBlock):\n",
    "        if isinstance(layer.bn1, layers.BatchNormalization):\n",
    "            layer.bn1.trainable = False\n",
    "        if isinstance(layer.bn2, layers.BatchNormalization):\n",
    "            layer.bn2.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True  # Esto es redundante, pero por si las moscas\n",
    "\n",
    "# Crear un nuevo modelo eliminando la última capa para agregar una nueva capa de salida\n",
    "model_layers = model.layers[:-1]\n",
    "new_model = models.Sequential(model_layers)\n",
    "\n",
    "# Añadir una nueva capa Dense con 10 neuronas para CIFAR-10\n",
    "new_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Resumen del nuevo modelo\n",
    "new_model.summary()\n",
    "\n",
    "# Configuración de parámetros de entrenamiento\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False)  # Usa softmax para la salida\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9, learning_rate=0.0001)\n",
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "\n",
    "# Crear dataset con data augmentation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Dataset de prueba\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Bucle de entrenamiento manual\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    epoch_loss_metric = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_dataset):\n",
    "        # Data Augmentation (aplica augmentación si es necesario)\n",
    "        augmented_images = data_augmentation(images)  # Aplicar augmentación aquí\n",
    "\n",
    "        # Forward pass y cálculo de gradientes\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = new_model(augmented_images, training=True)  # Propagación hacia adelante\n",
    "            loss = loss_function(labels, predictions)  # Cálculo de la pérdida\n",
    "\n",
    "        # Cálculo de gradientes y actualización de pesos\n",
    "        trainable_vars = [var for var in new_model.trainable_variables if var.trainable]\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Actualizar métricas\n",
    "        epoch_loss_metric.update_state(loss)\n",
    "        epoch_accuracy.update_state(labels, predictions)\n",
    "\n",
    "        # Imprimir cada ciertos pasos\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Loss = {loss.numpy():.4f}, Accuracy = {epoch_accuracy.result().numpy():.4f}\")\n",
    "\n",
    "    # Imprimir resultados al final de cada época\n",
    "    print(f\"Epoch {epoch + 1}: Loss = {epoch_loss / len(train_dataset):.4f}, Accuracy = {epoch_accuracy.result().numpy():.4f}\")\n",
    "\n",
    "# Evaluación en conjunto de prueba\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "new_model.compile(optimizer=optimizer, \n",
    "                        loss=loss_function, \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "test_loss, test_accuracy = new_model.evaluate(test_dataset)\n",
    "print(f\"Test Loss = {test_loss:.4f}, Test Accuracy = {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del resultado del conjunto de test.\n",
    "\n",
    "El modelo entrenado muestra un notable rendimiento en el conjunto de test, con una precisión de test de 85.99% y una pérdida de test de 0.4064, lo que indica un alto nivel de generalización. Durante el entrenamiento, la precisión aumentó de 25.00% a 84.86% y la pérdida disminuyó de 3.78 a 0.8648, mostrando una mejora constante. En las primeras épocas, la precisión creció rápidamente, estabilizándose entorno al 84% hacia el final del entrenamiento. Esta tendencia sugiere que el modelo ha aprendido los patrones de los datos de manera efectiva. La pequeña diferencia entre las métricas de entrenamiento y test indica que el modelo no presenta sobreajuste, ya que las métricas de test son casi tan altas como las de entrenamiento. En resumen, el modelo ha alcanzado un rendimiento excelente y consistente, con solo 20 épocas de entrenamiento, lo que demuestra su capacidad para generalizar bien a datos no vistos.\n",
    "\n",
    "Por último, podemos comprobar que empleando fit y el bucle, los resultados son similares."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6149794,
     "sourceId": 9992299,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
